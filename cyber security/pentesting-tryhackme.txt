PENETRATION TESTING
=======================================

Rules of Engagement doc:
 - contains:
	-> Permission
	-> Scope
	-> Rules

Pentest methodologies:
1. Information Gathering
2. Enumeration/Scanning
3. Exploitation
4. Privelege escalation
5. Post exploitation

The Open Source Security Testing Methodology Manual: https://www.isecom.org/OSSTMM.3.pdf

Open Web Application Security Project: https://owasp.org/

NIST Cybersecurity Framework 1.1: https://www.nist.gov/cyberframework

Cyber Assessment Framework: https://www.ncsc.gov.uk/collection/caf/caf-principles-and-guidance

CIA Triad:
- Confidentiality
- Integrity
- Availability

Principle of Privileges:
	1. Privileged Identity Management: create role that is based on user's role/responsibilities.
	2. Privileged Access Management:  manage the privileges an access role has.
	
Security models:
	1. The Bell-La Padula model
		- military style, top-secret stuff available to higher-up ranks.
		
	2. The Biba Model
		- a dev has access to code, but not the 
		
Threat model:
Threat modelling is the process of reviewing, improving, and testing the security protocols in place in an organisation's information technology infrastructure and services.

Threat model frameworks:
- STRIDE
- PASTA

STRIDE:
- Spoofing
- Tampering
- Repudiation
- Information Disclosure
- Denial of Service
- Escalation of privileges


Web-app pentesting:
- try listing the directory using a /assets on the page url. If directory listing is enabled, this could let us explore some files.

Content Discovery:
- can be:
	-> Manual
	-> Automated
	-> Open Source Intelligence (OSINT)

1. Robots.txt to see what pages they don't want to be publicly seen. accessed through {url}/robots.txt

2. look up default icons by checking the md5 hash of the icons and then looking it up on https://wiki.owasp.org/index.php/OWASP_favicon_database. This lets us identify the framework used to build the web app.

3. Sitemap: can sometimes contain areas of the website that are a bit more difficult to navigate to or even list some old webpages that the current site no longer uses but are still working behind the scenes. access it through {url}/sitemap.xml

4. HTTP headers: we could get information about web servers, php versions etc. access it through: curl -v {url}

5. Google Dorking/Hacking:
	site:tryhackme.com
	returns results only from the specified website address

	inurl:admin
	returns results that have the specified word in the URL

	filetype:pdf
	returns results which are a particular file extension

	intitle:admin
	returns results that contain the specified word in the title
	
6. Wappalyzer: Used to get the technology stacks used by websites https://www.wappalyzer.com/

7. Wayback machine: Historical lookback on webpages crawled and saved at different points in time dating back to the 90s. https://archive.org/web/

8. Automated tools for discovery:
	ffuf -w /usr/share/wordlists/SecLists/Discovery/Web-Content/common.txt -u http://10.10.172.194/FUZZ

	dirb http://10.10.172.194/ /usr/share/wordlists/SecLists/Discovery/Web-Content/common.txt

	gobuster dir --url http://10.10.172.194/ -w /usr/share/wordlists/SecLists/Discovery/Web-Content/common.txt


Subdomain enumeration:
- Three ways:
	1. Brute Force
	2. OSINT
	3. Virtual Host
	
	
 1. OSINT - SSL/TLS certificates:
	- https://crt.sh/
	- https://ui.ctsearch.entrust.com/ui/ctsearchui
	
 2. OSINT - Search engine : We can use the site: filter on Google search, like so: "-site:www.tryhackme.com site:*.tryhackme.com"
	This can show all the subdomains while excluding the www pages from the results.
	
 3. DNS Brute force:
	- https://www.kali.org/tools/dnsrecon/
	This uses a wordlist of commonly used subdomains and brute force to find the subdomains.
	This looks at DNS NS records, A records etc. 
	
 4. OSINT - Sublist3r
	- https://www.kali.org/tools/sublist3r/
	This automates looking up in multiple search engines (Google, Bing, Baidu, VirusTotal etc.) and finding the subdomains.
	
 5. Virtual hosts
	- Here it's a similar brute force but instead we send the server requests with different host headers.
	and depending on the response from the server, we can discover new subdomains.
	
	ffuf -w /usr/share/wordlists/SecLists/Discovery/DNS/namelist.txt -H "Host: FUZZ.acmeitsupport.thm" -u http://10.10.116.155 -fs 2395

	the -fs flag is so that we filter out (i.e., remove) all the responses with that size.

=====================================================================================================================================================================================	
Authentication Bypass

1. Username enumeration
	- to create a list of valid usernames, the easiest thing is to attempt a sign-up with various username strings and observe the response error message like "user already exists".
	- Again, we can use ffuf for this:
	
		ffuf \
		-w /usr/share/wordlists/SecLists/Usernames/Names/names.txt \    # username list
		-X POST -d "username=FUZZ&email=x&password=x&cpassword=x" \		# form content
		-H "Content-Type: application/x-www-form-urlencoded" \			# set content-type header to form with values in url
		-u http://10.10.96.68/customers/signup \						# sign up url
		-mr "username already exists"									# error message string to match against
		
2. Password brute forcing
	- To use the valid list of usernames and a password list, and brute force the f out of the login endpoint.
	
	ffuf \
	-w valid_usernames.txt:W1,/usr/share/wordlists/SecLists/Passwords/Common-Credentials/10-million-password-list-top-100.txt:W2 \
	-X POST -d "username=W1&password=W2" \
	-H "Content-Type: application/x-www-form-urlencoded" \
	-u http://10.10.96.68/customers/login \
	-fc 200
	
3. Application logic flaw:
	- We try to use any flaws in the authentication logic to gain access.
	- In the example scenario, the website was sending password reset email to an email associated to the account. 
	- The website prompts for an email of the account, then also asks for the username.
	- The email is collected through the query string param, and the username through a POST form variable.
	- The application logic uses the query string arg to fetch the account details and match the username with the user-entered username value. BUT, it then uses the PHP variable $_REQUEST to get the email address and send the reset email.
	- If there are both POST and GET variables of the same name, the application favors the POST variable from $_REQUEST. We exploit this and send another form variable 'email' when we make the request.
	- So the website uses the query string arg to validate the account, BUT it sends the reset email to the attacker's email id.
	
4. Cookie tampering
	- sometimes cookies might be setting the state of the user, such as logged_in=true/false or things like that.
	- so we can modify the cookie sent in our request to bypass authentication.
	
	Hashes
	Sometimes though cookie values won't be in plain text, but would contain some form of hash. In this case, we can use a hash lookup for e.g., https://crackstation.net/
	and find the original key.
	
======================================================================================================================================================================================

IDOR - Insecure Direct Object Reference
 - This kind of vulnerability occurs when a web-server uses user-supplied input to retrieve objects (files, data, documents) without validation on the server-side to verify that the requested object belongs to the user.
 - this is called an access control vulnerability.
 
 For e.g., this could be something as simple as changing the https://onlinestore.thm/order/1000/invoice to https://onlinestore.thm/order/1234/invoice
	
 - The IDs need not necessarily be passed in as plain text. For e.g., it could be encoded using base64 encoding or it could be sent as an md5 hash.
 In each of these cases, we can try to decode or use hash lookup to find the raw content.
 
 - If we can't find out the raw ID in anyway, we can create two accounts and swap the IDs between them. If we can view the other user's content while logged in as another user, then it's an IDOR vulnerability.
 
 IDORs doesn't necessarily have to be in the web page URL, it could also be in an endpoint where we make an AJAX request.
 
 There's also something called parameter mining which can be used to identify params that are not used by the web page, but is sort of hidden and still processed by the backend.
 Best way to detect this is using the network monitoring in the developer tools of a browser.
 
--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

File inclusion:
 1. Local File Inclusion:
	- occurs due to a web developer's lack of security awareness.
	- for e.g., PHP uses functions like include(), require(), include_once() and require_once() to load files in the server into the script.
	- So in cases where some user input is directly used as params for these functions WITHOUT VALIDATION, we can modify the input value to a file path in the server that we want to retrieve, like '/etc/passwd'.
	- Some specific edge cases:
		1) The include() function could specify a directory, like "languages/". In which case, we can use the double dot (../) to escape and traverse up to the root.
		   So something like "../../../../../etc/passwd".
		   
		2) Sometimes the developer may append file extensions to the files being retrieved, like '.php'. In this case, we can escape that by adding a '%00' (without the quotes) to the end of the user string we supply.
		
		3) To take it further, the developer might filter out certain strings like '/etc/passwd' - in which case, we can use the dot operator to mean we want the current directory. So it would be '/etc/passwd/.' which gets filtered to => '.' => which still returns the /etc/passwd file.
		
		4) Another step is when developers filter out '../' strings. But we can overcome this by adding double the characters like: '....//'. So the first set of ../ gets removed from this but the remaining characters end up being '../' which still gets the job done.
		
		5) The developer could also add a validation that the input string begins with the directory to limit to, like 'languages/blah...'. In this case, we can have the input string start with 'languages/../../' and move up using the ../ operator.